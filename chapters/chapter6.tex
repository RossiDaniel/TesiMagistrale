\hypertarget{(chap:capitolo6)}{}
\chapter{LIbreria cornac e esperimenti}
In questo capitolo  andremo a vedere le modalità con cui sono stati svolti gli esperimenti e la libreria utilizzata per gli stessi.

\section{Dataset}
Le informazioni dello storico vendite sono state organizzate basandosi sulle due macrocategorie individuate nell'analisi: macchine e ricambi.
Gli item considerati sono quelli acquistati almeno una volta mentre per i clienti quelli che hanno effettuato almeno un'acquisto.
Abbiamo quindi tre tipi matrici grezze user-item contenenti solo item appartenenti alle macrocategoria delle macchine, solo dei ricambi ed infine una con tutti gli item detta totale.
In generale le divisione rispetto i tipi di dataset sono le seguenti:
\begin{itemize}
    \item \textbf{Macchine}: 254 user e 518 item;
    \item \textbf{Ricambi}: 319 user e 7699 item;
    \item \textbf{Totale}: 322 user e 8217 item;
\end{itemize}

Per ognuno di questi tipi di matrice abbiamo le quattro versioni delle espressioni di interesse, che sono state calcolate tra uno user $u$ e un item $i$ come segue:
\begin{itemize}
    \item \textbf{Quantità}: somma dei campi quantità (\textit{KWMENG}) di tutte le posizione delle fatture di $u$ in cui è presente $i$.
    \item \textbf{Spesa totale}: somma dei campi spesa totale (\textit{NETWR}) di tutte le posizione delle fatture di $u$ in cui è presente $i$.
    \item \textbf{Numero di fatture}: conta del numero di fatture di $u$ in cui compare $i$.
    \item \textbf{Recentezza}: ricerca della posizione di $i$ nelle fatture di $u$, riportante la data più recente di acquisto. Se l'item è stato acquistato avremo quindi una data a cui andremo a sottrarre la data della fattura più vecchia, il delta temporale viene trasformato in giorni. Quindi più è alto il delta in giorni più recente sarà l'acquisto.
\end{itemize}

\section{Libreria Cornac}
La libreria cornac gestisce completamente gli esperimenti, dall'acquisizione dei dati fino alla verifica dei risultati.
Nello specifico è stata scelta per la presenza di molti \textit{modelli} e metriche per la loro valutazione.\\
Nello specifico i modelli utilizzati sono stati:
\begin{itemize}
    \item MostPop: modello basato sulla popolarità, dove un item è più popolare in base al numero di user che lo hanno valutato, usato per ottenere un risultato di base;
    \item UserKnn: implementazione dell'approccio del collaborative filtering memory-based, che di default prende in considerazione i 20 user più simili ad uno target.
    \item ItemKnn: come il precedente, ma basato sugli item. Non è stato infine utilizzato in quanto durante le fasi iniziali di test non ha mai riportato risultati superiori a quelli di base e richiedeva troppo tempo per la valutazione;
    \item MF: implementazione del matrix factorization, metodo model-based del collaborative filtering, di default considera 10 user più simili ad uno target;
    \item VAECF: modello per la versione implicita, usato per avere un risultato di base.
\end{itemize}
I dati presi in input sono nel formato \textit{user, item, rating} e volendo potevano essere divisi in training, validation e test set direttamente dalla libreria.
Si è preferito però dividerli esternamente con le rispettive percentuali: 70\% al training set, 15\% per validation e test set.
Nella fase di valutazione dei risultati dei \textit{modelli} veniva richiesto un parametro detto \textit{rating\_threshold}, il quale serviva a binarizzare gli item rilevanti e irrilevanti del test set basandosi sul rating corrispondente. Non andava in alcun modo ad intaccare i rating nella fare di training.
 
\section{Esperimenti sulle singole matrici dei rating}
Come riportato nel capitolo relativo il preprocessing delle matrici grezze, non è stata definita una scala dei rating in quanto se ne volevano provare diverse: 3, 5, 7, 9, 13, 19, 25.
Inoltre per ogni tecnica dove fosse previsto l'utilizzo di una delle distribuzioni disponibili, si è proceduto a testarle entrambe.
Dalle combinazioni di diversa scala e distribuzione dei rating, unito con la presenza di ben dodici matrici grezze (3 tipi di dataset per 4 espressioni di interesse) si sono ottenute circa 1500 matrici grezze.
Per eseguire i test si è proceduti come segue:
\begin{enumerate}
    \item Ottengo un risultato di base con il modello MostPop e con il VAECF;
    \item Poi per ogni combinazione di matrice dei rating, scala e funzione di distribuzione se usata, si eseguono le seguenti operazioni:
    \begin{enumerate}
        \item \textit{Alleno} il modello con valori di deafult con il training set;
        \item valuto i risultati del modello sul validation set, se questi valori risultano migliori di quelli di base (dati dal MostPop e VAECF), allora si procede ad un tuning dei parametri;
        \item Una volta concluso il tuning, si sceglie il modello migliore in accordo al validation set;
        \item Si restituisce la valutazione finale basata su test set.
    \end{enumerate}
\end{enumerate}

\section{Esperimenti sulle matrici dei rating combinate}
Questi esperimenti sono stati condotti andando a combinare insieme secondo le modalità indicate solo le matrici dei rating generate con lo stessa tecnica e sulla stessa scala.
